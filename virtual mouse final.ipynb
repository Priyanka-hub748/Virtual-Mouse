{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdad81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pyautogui\n",
    "import time\n",
    "import math\n",
    "import speech_recognition as sr\n",
    "import pyaudio\n",
    "\n",
    "dragging = False  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b26973",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pyautogui\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "hand_detector = mp.solutions.hands.Hands(\n",
    "    max_num_hands=2,\n",
    "    min_detection_confidence=0.7,\n",
    "    min_tracking_confidence=0.7\n",
    ")\n",
    "drawing_utils = mp.solutions.drawing_utils\n",
    "\n",
    "screen_width, screen_height = pyautogui.size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a204dbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "prev_x, prev_y = 0, 0\n",
    "smoothening = 5\n",
    "dragging = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c1ca96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)  \n",
    "\n",
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "hand_detector = mp_hands.Hands(\n",
    "    max_num_hands=1, \n",
    "    min_detection_confidence=0.7,\n",
    "    min_tracking_confidence=0.7\n",
    ")\n",
    "\n",
    "drawing_utils = mp.solutions.drawing_utils\n",
    "\n",
    "while True:\n",
    "    success, frame = cap.read()\n",
    "    if not success:\n",
    "        print(\"Failed to capture image\")\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    \n",
    "    frame_height, frame_width, _ = frame.shape\n",
    "\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    output = hand_detector.process(rgb_frame)\n",
    "    hands = output.multi_hand_landmarks  \n",
    "\n",
    "    if hands:\n",
    "        for hand_landmarks in hands:\n",
    "            drawing_utils.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "    cv2.imshow(\"Hand Landmarks Detection\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a621c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "hand_detector = mp.solutions.hands.Hands(\n",
    "    max_num_hands=1, \n",
    "    min_detection_confidence=0.7, \n",
    "    min_tracking_confidence=0.7\n",
    ")\n",
    "drawing_utils = mp.solutions.drawing_utils\n",
    "\n",
    "while True:\n",
    "    success, frame = cap.read()\n",
    "    if not success:\n",
    "        print(\"Failed to capture image\")\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    \n",
    "    frame_height, frame_width, _ = frame.shape\n",
    "\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    output = hand_detector.process(rgb_frame)\n",
    "    hands = output.multi_hand_landmarks\n",
    "\n",
    "    if hands:\n",
    "        for hand_landmarks in hands:\n",
    "            drawing_utils.draw_landmarks(frame, hand_landmarks)\n",
    "            landmarks = hand_landmarks.landmark\n",
    "\n",
    "            index_finger = landmarks[8]\n",
    "            thumb_finger = landmarks[4]\n",
    "            \n",
    "            index_x = int(index_finger.x * frame_width)\n",
    "            index_y = int(index_finger.y * frame_height)\n",
    "            thumb_x = int(thumb_finger.x * frame_width)\n",
    "            thumb_y = int(thumb_finger.y * frame_height)\n",
    "\n",
    "            cv2.circle(frame, (index_x, index_y), 10, (0, 255, 255), cv2.FILLED)\n",
    "            cv2.circle(frame, (thumb_x, thumb_y), 10, (0, 255, 255), cv2.FILLED)\n",
    "\n",
    "    cv2.imshow(\"Hand Landmarks and Finger Circles\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548f73b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pyautogui\n",
    "\n",
    "cap = cv2.VideoCapture(0)  \n",
    "\n",
    "hand_detector = mp.solutions.hands.Hands(\n",
    "    max_num_hands=1, \n",
    "    min_detection_confidence=0.7, \n",
    "    min_tracking_confidence=0.7\n",
    ")\n",
    "drawing_utils = mp.solutions.drawing_utils\n",
    "\n",
    "screen_width, screen_height = pyautogui.size()  \n",
    "\n",
    "prev_x, prev_y = 0, 0\n",
    "\n",
    "while True:\n",
    "    success, frame = cap.read()\n",
    "    if not success:\n",
    "        print(\"Failed to capture image\")\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    \n",
    "    frame_height, frame_width, _ = frame.shape\n",
    "\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    output = hand_detector.process(rgb_frame)\n",
    "    hands = output.multi_hand_landmarks  \n",
    "\n",
    "    if hands:\n",
    "        for hand_landmarks in hands:\n",
    "            drawing_utils.draw_landmarks(frame, hand_landmarks)\n",
    "            landmarks = hand_landmarks.landmark\n",
    "\n",
    "            index_finger = landmarks[8]\n",
    "            thumb_finger = landmarks[4]\n",
    "            \n",
    "            index_x = int(index_finger.x * frame_width)\n",
    "            index_y = int(index_finger.y * frame_height)\n",
    "\n",
    "            curr_x = prev_x + (index_x - prev_x) / smoothening\n",
    "            curr_y = prev_y + (index_y - prev_y) / smoothening\n",
    "\n",
    "            pyautogui.moveTo(curr_x * screen_width / frame_width, curr_y * screen_height / frame_height)\n",
    "\n",
    "            prev_x, prev_y = curr_x, curr_y\n",
    "\n",
    "    cv2.imshow(\"Hand Landmarks and Mouse Control\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c97708d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pyautogui\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "hands = mp.solutions.hands.Hands(max_num_hands=1, min_detection_confidence=0.8, min_tracking_confidence=0.8)\n",
    "drawing = mp.solutions.drawing_utils\n",
    "screen_width, screen_height = pyautogui.size()\n",
    "\n",
    "prev_x, prev_y = 0, 0\n",
    "alpha = 0.1\n",
    "dead_zone = 15\n",
    "dragging = False\n",
    "cooldown = 2\n",
    "last_back = last_vol_up = last_vol_down = 0\n",
    "\n",
    "def distance(p1, p2, w, h):\n",
    "    return math.hypot(int(p1.x * w) - int(p2.x * w), int(p1.y * h) - int(p2.y * h))\n",
    "\n",
    "x_margin = 0.2\n",
    "y_margin = 0.2\n",
    "\n",
    "while True:\n",
    "    success, frame = cap.read()\n",
    "    if not success:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    h, w, _ = frame.shape\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    result = hands.process(rgb)\n",
    "    landmarks = result.multi_hand_landmarks\n",
    "\n",
    "    if landmarks:\n",
    "        for hand in landmarks:\n",
    "            drawing.draw_landmarks(frame, hand)\n",
    "            lm = hand.landmark\n",
    "\n",
    "            index_tip = lm[8]\n",
    "            middle_tip = lm[12]\n",
    "            ring_tip = lm[16]\n",
    "            thumb_tip = lm[4]\n",
    "\n",
    "            index_x = int(index_tip.x * w)\n",
    "            index_y = int(index_tip.y * h)\n",
    "            cv2.circle(frame, (index_x, index_y), 10, (0, 255, 255), cv2.FILLED)\n",
    "\n",
    "            if not (x_margin < index_tip.x < 1 - x_margin and y_margin < index_tip.y < 1 - y_margin):\n",
    "                continue\n",
    "\n",
    "            mx = np.clip((index_tip.x - x_margin) / (1 - 2 * x_margin), 0, 1)\n",
    "            my = np.clip((index_tip.y - y_margin) / (1 - 2 * y_margin), 0, 1)\n",
    "            target_x = int(mx * screen_width)\n",
    "            target_y = int(my * screen_height)\n",
    "\n",
    "            curr_x = (1 - alpha) * prev_x + alpha * target_x\n",
    "            curr_y = (1 - alpha) * prev_y + alpha * target_y\n",
    "\n",
    "            if abs(curr_x - prev_x) > dead_zone or abs(curr_y - prev_y) > dead_zone:\n",
    "                pyautogui.moveTo(curr_x, curr_y)\n",
    "                prev_x, prev_y = curr_x, curr_y\n",
    "\n",
    "            now = time.time()\n",
    "            thumb_index_dist = distance(thumb_tip, index_tip, w, h)\n",
    "            thumb_ring_dist = distance(thumb_tip, ring_tip, w, h)\n",
    "\n",
    "            if thumb_index_dist < 45:\n",
    "                if not dragging:\n",
    "                    pyautogui.mouseDown()\n",
    "                    dragging = True\n",
    "            else:\n",
    "                if dragging:\n",
    "                    pyautogui.mouseUp()\n",
    "                    dragging = False\n",
    "\n",
    "            if thumb_ring_dist < 45 and now - last_back > cooldown:\n",
    "                pyautogui.hotkey('alt', 'left')\n",
    "                last_back = now\n",
    "\n",
    "            if index_tip.y < lm[6].y and middle_tip.y < lm[10].y and ring_tip.y < lm[14].y:\n",
    "                if now - last_vol_up > cooldown:\n",
    "                    pyautogui.press(\"volumeup\")\n",
    "                    last_vol_up = now\n",
    "\n",
    "            if index_tip.y < lm[6].y and middle_tip.y > lm[10].y and ring_tip.y > lm[14].y:\n",
    "                if now - last_vol_down > cooldown:\n",
    "                    pyautogui.press(\"volumedown\")\n",
    "                    last_vol_down = now\n",
    "\n",
    "    cv2.imshow(\"🖐 Gesture Mouse\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf7dd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyautogui\n",
    "import speech_recognition as sr\n",
    "import time\n",
    "import sys\n",
    "\n",
    "recognizer = sr.Recognizer()\n",
    "mic = sr.Microphone()\n",
    "\n",
    "# Calibrate mic\n",
    "with mic as source:\n",
    "    print(\"🎤 Calibrating microphone... Please wait.\")\n",
    "    recognizer.adjust_for_ambient_noise(source)\n",
    "    print(\"🎤 Microphone calibrated. You can speak now.\")\n",
    "\n",
    "# Voice command loop\n",
    "while True:\n",
    "    with mic as source:\n",
    "        print(\"🎧 Listening for command...\")\n",
    "        try:\n",
    "            audio = recognizer.listen(source, timeout=5)\n",
    "            command = recognizer.recognize_google(audio).lower()\n",
    "            print(\"🗣️ Command received:\", command)\n",
    "\n",
    "            # Mouse click commands\n",
    "            if \"click\" in command:\n",
    "                pyautogui.click()\n",
    "            elif \"double click\" in command:\n",
    "                pyautogui.doubleClick()\n",
    "            elif \"right click\" in command:\n",
    "                pyautogui.click(button='right')\n",
    "\n",
    "            # Scroll commands\n",
    "            elif \"scroll up\" in command:\n",
    "                pyautogui.scroll(300)\n",
    "            elif \"scroll down\" in command:\n",
    "                pyautogui.scroll(-300)\n",
    "            elif \"scroll right\" in command:\n",
    "                pyautogui.keyDown('shift')\n",
    "                pyautogui.scroll(-300)\n",
    "                pyautogui.keyUp('shift')\n",
    "            elif \"scroll left\" in command:\n",
    "                pyautogui.keyDown('shift')\n",
    "                pyautogui.scroll(300)\n",
    "                pyautogui.keyUp('shift')\n",
    "\n",
    "            # Volume commands\n",
    "            elif \"volume up\" in command:\n",
    "                pyautogui.press(\"volumeup\")\n",
    "            elif \"volume down\" in command:\n",
    "                pyautogui.press(\"volumedown\")\n",
    "\n",
    "            # Zoom commands\n",
    "            elif \"zoom in\" in command:\n",
    "                pyautogui.hotkey('ctrl', '+')\n",
    "            elif \"zoom out\" in command:\n",
    "                pyautogui.hotkey('ctrl', '-')\n",
    "\n",
    "            # Exit command\n",
    "            elif \"exit\" in command or \"close\" in command:\n",
    "                print(\"🛑 Voice command 'exit' detected. Exiting program...\")\n",
    "                pyautogui.alert(\"Voice Mouse Control: Exiting Program\")\n",
    "                sys.exit()\n",
    "\n",
    "        except sr.WaitTimeoutError:\n",
    "            print(\"⏱ Timeout: No voice input.\")\n",
    "        except sr.UnknownValueError:\n",
    "            print(\"🤷 Didn't catch that.\")\n",
    "        except Exception as e:\n",
    "            print(f\"❗ Error: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
